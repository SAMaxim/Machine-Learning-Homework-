{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключение библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 20:26:44.827235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 20:26:45.925499: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-02 20:26:48.654476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 20:26:48.654634: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 20:26:48.654647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import string\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основной код:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С сайта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFromWebsite = pd.DataFrame()\n",
    "dataFromWebsite['Text'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AUF.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "def findElement(number):\n",
    "    img_element = soup.find('img', class_='lazy lazy-hidden alignnone wp-image-' + str(number) + ' size-full')\n",
    "\n",
    "    if img_element:\n",
    "        parent_p_element = img_element.parent\n",
    "\n",
    "        next_p_element = parent_p_element.find_next_sibling('p')\n",
    "\n",
    "        if next_p_element:\n",
    "            text = next_p_element.get_text()\n",
    "\n",
    "            return text\n",
    "        else:\n",
    "            print('Next <p> element not found.')\n",
    "    else:\n",
    "        print('Image element not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n",
      "Image element not found.\n"
     ]
    }
   ],
   "source": [
    "for k in range(2968, 3022):\n",
    "    dataFromWebsite.loc[len(dataFromWebsite.index)] = [findElement(k)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Лучше быть последним — первым, чем первым — по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>На случай, если буду нужен, то я там же, где и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Если волк молчит то лучше его не перебивай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Каждый в цирке думает, что знает в цирке, но н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Легко вставать, когда ты не ложился.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Лучше быть последним — первым, чем первым — по...\n",
       "1  На случай, если буду нужен, то я там же, где и...\n",
       "2        Если волк молчит то лучше его не перебивай.\n",
       "3  Каждый в цирке думает, что знает в цирке, но н...\n",
       "4               Легко вставать, когда ты не ложился."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFromWebsite.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С другого сайта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFromWebsites = pd.DataFrame()\n",
    "dataFromWebsites['Text'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAll(url):\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_ = 'ads-color-box')\n",
    "    \n",
    "    if div_elements:\n",
    "        contents = [div.text.strip() for div in div_elements]\n",
    "        return contents\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://citatko.com/bez-rubriki/auf-tsitaty-pro-volkov'\n",
    "dataFromWebsite1 = parseAll(url1)\n",
    "\n",
    "url2 = 'https://citatko.com/temy/volk/tsitaty-pro-odinokogo-volka'\n",
    "dataFromWebsite2 = parseAll(url2)\n",
    "\n",
    "url3 = 'https://citatko.com/temy/volk/patsanskie-tsitaty-pro-volkov'\n",
    "dataFromWebsite3 = parseAll(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in dataFromWebsite1:\n",
    "    dataFromWebsites.loc[len(dataFromWebsites.index)] = [content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in dataFromWebsite2:\n",
    "    dataFromWebsites.loc[len(dataFromWebsites.index)] = [content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in dataFromWebsite3:\n",
    "    dataFromWebsites.loc[len(dataFromWebsites.index)] = [content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Лучше быть последним – первым, чем первым – по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кем бы ты ни был, кем бы ты не стал, помни, гд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Если волк молчит то лучше его не перебивать.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Делай как надо, как не надо не делай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Работа не волк, работа это ворк, а волк это хо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Лучше быть последним – первым, чем первым – по...\n",
       "1  Кем бы ты ни был, кем бы ты не стал, помни, гд...\n",
       "2       Если волк молчит то лучше его не перебивать.\n",
       "3              Делай как надо, как не надо не делай.\n",
       "4  Работа не волк, работа это ворк, а волк это хо..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFromWebsites.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### С файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFromFile = pd.read_fwf('slogans.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Я знал настоящего волка — он был просрочен и к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Волк может отгрызть себе жопу чтобы не стать п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Хочешь, будь волком. Это твоё дело. Главное на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В этой жизни ты либо волк, либо не волк.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Если волк молчит, то лучше его не перебивай.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Я знал настоящего волка — он был просрочен и к...\n",
       "1  Волк может отгрызть себе жопу чтобы не стать п...\n",
       "2  Хочешь, будь волком. Это твоё дело. Главное на...\n",
       "3           В этой жизни ты либо волк, либо не волк.\n",
       "4       Если волк молчит, то лучше его не перебивай."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFromFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([dataFromWebsite, dataFromFile, dataFromWebsites], ignore_index = True, sort = False)\n",
    "data.dropna(inplace = True)\n",
    "data.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Лучше быть последним — первым, чем первым — по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>На случай, если буду нужен, то я там же, где и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Если волк молчит то лучше его не перебивай.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Каждый в цирке думает, что знает в цирке, но н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Легко вставать, когда ты не ложился.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Главное не образ льва, а дух волка. И волки сы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Волк на холме не так голоден, как волк, взбира...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Щедрому волку не жалко травы для барана, а жад...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Волки не ждут предательства от своих в стае — ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>У собаки — хозяин, а у волка — Бог.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "0    Лучше быть последним — первым, чем первым — по...\n",
       "1    На случай, если буду нужен, то я там же, где и...\n",
       "2          Если волк молчит то лучше его не перебивай.\n",
       "3    Каждый в цирке думает, что знает в цирке, но н...\n",
       "4                 Легко вставать, когда ты не ложился.\n",
       "..                                                 ...\n",
       "227  Главное не образ льва, а дух волка. И волки сы...\n",
       "228  Волк на холме не так голоден, как волк, взбира...\n",
       "229  Щедрому волку не жалко травы для барана, а жад...\n",
       "230  Волки не ждут предательства от своих в стае — ...\n",
       "231                У собаки — хозяин, а у волка — Бог.\n",
       "\n",
       "[232 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "def preprocessText(text):\n",
    "    whitelist = set('ёйцукенгшщзхъфывапролджэячсмитьбю ЁЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ')\n",
    "    text = ''.join(filter(whitelist.__contains__, text))\n",
    "    text = text.lower()\n",
    "    text = ''.join(m.lemmatize(text)).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prepText'] = data['Text'].apply(preprocessText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>prepText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Лучше быть последним — первым, чем первым — по...</td>\n",
       "      <td>хорошо быть последний  первый чем первый  посл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>На случай, если буду нужен, то я там же, где и...</td>\n",
       "      <td>на случай если быть нужный то я там же где и б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Если волк молчит то лучше его не перебивай.</td>\n",
       "      <td>если волк молчать то хорошо он не перебивать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Каждый в цирке думает, что знает в цирке, но н...</td>\n",
       "      <td>каждый в цирк думать что знать в цирк но не ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Легко вставать, когда ты не ложился.</td>\n",
       "      <td>легко вставать когда ты не ложиться</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Главное не образ льва, а дух волка. И волки сы...</td>\n",
       "      <td>главное не образ лев а дух волк и волк сытый и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Волк на холме не так голоден, как волк, взбира...</td>\n",
       "      <td>волк на холм не так голодный как волк взбирать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Щедрому волку не жалко травы для барана, а жад...</td>\n",
       "      <td>щедрый волк не жалко трава для баран а жадный ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Волки не ждут предательства от своих в стае — ...</td>\n",
       "      <td>волк не ждать предательство от свой в стая  он...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>У собаки — хозяин, а у волка — Бог.</td>\n",
       "      <td>у собака  хозяин а у волк  бог</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  \\\n",
       "0    Лучше быть последним — первым, чем первым — по...   \n",
       "1    На случай, если буду нужен, то я там же, где и...   \n",
       "2          Если волк молчит то лучше его не перебивай.   \n",
       "3    Каждый в цирке думает, что знает в цирке, но н...   \n",
       "4                 Легко вставать, когда ты не ложился.   \n",
       "..                                                 ...   \n",
       "227  Главное не образ льва, а дух волка. И волки сы...   \n",
       "228  Волк на холме не так голоден, как волк, взбира...   \n",
       "229  Щедрому волку не жалко травы для барана, а жад...   \n",
       "230  Волки не ждут предательства от своих в стае — ...   \n",
       "231                У собаки — хозяин, а у волка — Бог.   \n",
       "\n",
       "                                              prepText  \n",
       "0    хорошо быть последний  первый чем первый  посл...  \n",
       "1    на случай если быть нужный то я там же где и б...  \n",
       "2         если волк молчать то хорошо он не перебивать  \n",
       "3    каждый в цирк думать что знать в цирк но не ка...  \n",
       "4                  легко вставать когда ты не ложиться  \n",
       "..                                                 ...  \n",
       "227  главное не образ лев а дух волк и волк сытый и...  \n",
       "228  волк на холм не так голодный как волк взбирать...  \n",
       "229  щедрый волк не жалко трава для баран а жадный ...  \n",
       "230  волк не ждать предательство от свой в стая  он...  \n",
       "231                     у собака  хозяин а у волк  бог  \n",
       "\n",
       "[232 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 14 24 28  3  1 21 20  4 17  1 18  2 11  9  3 13  6  7 15  1 33  1 18\n",
      "  3 12  8 20 15 16  1 24  3 15  1 18  3 12  8 20 15  1 33  1 18  2 11  9\n",
      "  3 13  6  7 15 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level = False)\n",
    "\n",
    "tokenizer.fit_on_texts(data['Text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data['Text'])\n",
    "\n",
    "sequences = pad_sequences(sequences, padding = 'post')\n",
    "\n",
    "least_freq_word = min(tokenizer.word_index, key = tokenizer.word_index.get)\n",
    "\n",
    "print(sequences[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объявление нейронки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SloganGenerator(nn.Module):\n",
    "    def __init__(self, vocabularySize, embeddingDim, hiddenDim, numLayers):\n",
    "        super(SloganGenerator, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocabularySize, embeddingDim)\n",
    "        self.lstm = nn.LSTM(embeddingDim, hiddenDim, numLayers, batch_first = True)\n",
    "        self.fc = nn.Linear(hiddenDim, vocabularySize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SloganGenerator(\n",
      "  (embedding): Embedding(49, 256)\n",
      "  (lstm): LSTM(256, 128, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=49, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocabularySize = len(tokenizer.word_index) + 1\n",
    "embeddingDim = 256\n",
    "hiddenDim = 128\n",
    "numLayers = 2\n",
    "\n",
    "model = SloganGenerator(vocabularySize, embeddingDim, hiddenDim, numLayers)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300, Loss: 0.7429830431938171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m output \u001b[39m=\u001b[39m model(inputSequences)\n\u001b[1;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), targetSequences)\n\u001b[0;32m---> 18\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "sequencesTensor = torch.tensor(sequences).long()\n",
    "\n",
    "inputSequences = sequencesTensor[:, :-1].to(device)\n",
    "targetSequences = sequencesTensor[:, 1:].to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "numEpochs = 300 # Подобрать\n",
    "for epoch in range(numEpochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputSequences)\n",
    "\n",
    "    loss = criterion(output.transpose(1, 2), targetSequences)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{numEpochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем слоганы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSlogan(model, tokenizer, seedText, minWordLength = 10, maxWordLength = 12, temperature = 2):\n",
    "    model.eval()\n",
    "\n",
    "    seed_words = seedText.lower().split()\n",
    "\n",
    "    input_sequence = [tokenizer.word_index.get(word, tokenizer.word_index[least_freq_word]) for word in seed_words]\n",
    "    slogan = \"\"\n",
    "\n",
    "    while len(slogan.split()) < minWordLength or len(slogan.split()) > maxWordLength:\n",
    "        input_sequence_tensor = torch.tensor([input_sequence]).long().to(device)\n",
    "        output = model(input_sequence_tensor)\n",
    "\n",
    "        output_probs = torch.softmax(output / temperature, dim = -1)\n",
    "\n",
    "        next_token = torch.multinomial(output_probs[:, -1], num_samples = 1).item()\n",
    "\n",
    "        input_sequence.append(next_token)\n",
    "\n",
    "        slogan = ' '.join(tokenizer.index_word.get(token, '') for token in input_sequence[1:])\n",
    "\n",
    "    slogan = ' '.join(slogan.split()[:maxWordLength])\n",
    "\n",
    "    return f'{seedText} - {slogan}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данила - верь тому кому не веришь ведь вера в не веру\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Данила'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Волк - – единственный из зверей который может пойти в бой на более сильного\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Волк'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Волк - никогда не легко настоящих не укусил но и своих приручить\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Волк'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Саша - поставит внутри в санитар может меня думает уперты волчья легенда\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Саша')) # temperature = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максим - ударов тот на слабее забывают вырос волку оступиться… видит жадному\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Максим'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Артём - душит сыр со раньше нов свое зато удивленно встал волчица\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Артём'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Саня - смотрите что бьют не так уже довольствуется вашей маской человеку\n"
     ]
    }
   ],
   "source": [
    "print(generateSlogan(model, tokenizer, 'Саня'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бонус: генерируем картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.transform import swirl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = 'images.json'\n",
    "\n",
    "def chooseRandomElement():\n",
    "    with open(json_file, 'r') as file:\n",
    "        JSONData = json.load(file)\n",
    "\n",
    "    random.seed(random.seed(datetime.now().timestamp()))\n",
    "\n",
    "    randomElement = random.choice(JSONData)\n",
    "    return randomElement\n",
    "\n",
    "def putTextOnImage(image, topLeft, width, height, text):\n",
    "    overlay = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    fontFace = cv2.FONT_HERSHEY_COMPLEX\n",
    "    fontColor = (255, 255, 255)\n",
    "\n",
    "    # bottomRight = (topLeft[0] + width, topLeft[1] + height)\n",
    "    # cv2.rectangle(overlay, topLeft, bottomRight, (0, 0, 255), -1)\n",
    "\n",
    "    # Try different font sizes until the text fits inside the rectangle\n",
    "    fontScale = 1\n",
    "    while True:\n",
    "        lines = []\n",
    "        line = ''\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            line_test = line + ' ' + word if line else word\n",
    "            text_size, _ = cv2.getTextSize(line_test, fontFace, fontScale, 1)\n",
    "            if text_size[0] <= width:\n",
    "                line = line_test\n",
    "            else:\n",
    "                lines.append(line)\n",
    "                line = word\n",
    "        lines.append(line)\n",
    "\n",
    "        line_height = text_size[1]\n",
    "        if line_height * len(lines) <= height:\n",
    "            break\n",
    "        fontScale -= 0.3\n",
    "\n",
    "    text_org = (topLeft[0] + int((width - width) / 2), topLeft[1] + int((height - line_height * len(lines)) / 2))\n",
    "    for line in lines:\n",
    "        cv2.putText(overlay, line, text_org, fontFace, fontScale, fontColor, 1, cv2.LINE_4)\n",
    "        text_org = (text_org[0], text_org[1] + line_height)\n",
    "\n",
    "    result = cv2.addWeighted(image, 1, overlay, 0.5, 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "def generatePicture(model, tokenizer, seedText, generateBool = True):\n",
    "    if generateBool:\n",
    "        text = generateSlogan(model, tokenizer, seedText)\n",
    "    else:\n",
    "        text = seedText\n",
    "\n",
    "    randomImage = chooseRandomElement()\n",
    "\n",
    "    img = cv2.imread(randomImage['path_to_picture'])\n",
    "\n",
    "    Cx = randomImage['coordinates']['x']\n",
    "    Cy = randomImage['coordinates']['y']\n",
    "\n",
    "    maxAmount = 3\n",
    "    radius = randomImage['radius']\n",
    "    angle = 0\n",
    "    numFrames = 50\n",
    "    delay = 1\n",
    "\n",
    "    Tx = randomImage['text_coordinates']['x']\n",
    "    Ty = randomImage['text_coordinates']['y']\n",
    "\n",
    "    Tw = randomImage['text_coordinates']['w']\n",
    "    Th = randomImage['text_coordinates']['h']\n",
    "\n",
    "    frames = []\n",
    "    # Loop and increase swirl\n",
    "    for i in range(0, numFrames):\n",
    "        amount = i * maxAmount / numFrames\n",
    "\n",
    "        result = swirl(img, center = (Cx,Cy), rotation = angle, strength = amount, radius = radius, preserve_range = True).astype(np.uint8)\n",
    "\n",
    "        result = putTextOnImage(result, (Tx, Ty), Tw, Th, text)\n",
    "\n",
    "        cv2.waitKey(delay)\n",
    "\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "        pilResult = Image.fromarray(result)\n",
    "        frames.append(pilResult)\n",
    "\n",
    "    frames[0].save(str(seedText) + '.gif',save_all = True, append_images = frames[1:], optimize = False, duration = delay, loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePicture(model, tokenizer, 'Артем')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePicture(model, tokenizer, 'Пенис')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatePicture(model, tokenizer, 'Данила')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
