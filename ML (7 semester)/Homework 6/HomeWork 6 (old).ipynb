{"cells":[{"cell_type":"code","source":["!pip install catboost"],"metadata":{"id":"krefvOwbT-Du","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683642855539,"user_tz":-180,"elapsed":8636,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}},"outputId":"d23c662b-d5d9-4f2d-cfe7-a57f4f784457"},"id":"krefvOwbT-Du","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting catboost\n","  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n","Installing collected packages: catboost\n","Successfully installed catboost-1.2\n"]}]},{"cell_type":"markdown","source":["# Подключение библиотек:"],"metadata":{"id":"vr4yTt_gX0bW"},"id":"vr4yTt_gX0bW"},{"cell_type":"code","source":["import math\n","import pickle\n","import random\n","from typing import List, Tuple\n","\n","import numpy as np\n","import torch\n","from catboost.datasets import msrank_10k\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.tree import DecisionTreeRegressor\n","from tqdm.auto import tqdm"],"metadata":{"id":"gJ-98L4BXyEn","executionInfo":{"status":"ok","timestamp":1683642860469,"user_tz":-180,"elapsed":1797,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}}},"id":"gJ-98L4BXyEn","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Реализация:"],"metadata":{"id":"OZs3B1GjX8Wt"},"id":"OZs3B1GjX8Wt"},{"cell_type":"code","source":["def compute_gain(y_value: float, gain_scheme: str) -> float:\n","    if gain_scheme == 'const':\n","        return float(y_value)\n","    elif gain_scheme == 'exp2':\n","        return float(2 ** y_value - 1)\n","    return float(\"inf\")"],"metadata":{"id":"tmOpgaw2Xg3R","executionInfo":{"status":"ok","timestamp":1683642911606,"user_tz":-180,"elapsed":3,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}}},"id":"tmOpgaw2Xg3R","execution_count":4,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed: int) -> None:\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","\n","def dcg(ys_true: torch.FloatTensor, ys_pred: torch.FloatTensor, gain_scheme: str =\"exp2\", k: int = None) -> float:\n","    k = k or ys_true.size(dim=0)\n","    if k > ys_true.size(dim=0):\n","        k = ys_true.size(dim=0)\n","    idx = torch.argsort(ys_pred, descending=True)\n","    true_sorted = ys_true[idx].to(torch.float64)\n","    steps = torch.arange(2, k + 2, dtype=torch.float64)\n","    steps = torch.log2(steps)\n","    gains = true_sorted.apply_(lambda x: compute_gain(x, gain_scheme))[0:k]\n","    return float(torch.sum(gains / steps))\n","\n","def ndcg(ys_true: torch.FloatTensor, ys_pred: torch.FloatTensor, gain_scheme: str = 'exp2', k: int = None) -> float:\n","    k = k or ys_true.size(dim=0)\n","    if k > ys_true.size(dim=0):\n","        k =  ys_true.size(dim=0)\n","    dcg_score = dcg(ys_true, ys_pred, gain_scheme, k)\n","    true_sorted, _ = torch.sort(ys_true, descending=True)\n","    ideal_dcg = dcg(true_sorted, true_sorted, gain_scheme, k)\n","    return float(dcg_score / ideal_dcg)"],"metadata":{"id":"ubKNVMVgMSGE","executionInfo":{"status":"ok","timestamp":1683642913075,"user_tz":-180,"elapsed":4,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}}},"id":"ubKNVMVgMSGE","execution_count":5,"outputs":[]},{"cell_type":"code","source":["class Solution:\n","    def __init__(self, n_estimators: int = 100, lr: float = 0.5, ndcg_top_k: int = 10,\n","                 subsample: float = 0.6, colsample_bytree: float = 0.9,\n","                 max_depth: int = 5, min_samples_leaf: int = 8):\n","        self.X_train = None\n","        self.ys_train = None\n","        self.X_test = None\n","        self.ys_test = None\n","        self._prepare_data()\n","\n","        self.ndcg_top_k = ndcg_top_k\n","        self.n_estimators = n_estimators  # количество деревьев\n","        self.lr = lr  # Learning Rate, коэффициент, на который умножаются предсказания каждого нового дерева\n","        self.max_depth = max_depth  # максимальная глубина\n","        self.min_samples_leaf = min_samples_leaf  # минимальное количество термальных листьев\n","\n","        self.subsample = subsample  # доля объектов от выборки\n","        self.colsample_bytree = colsample_bytree  # доля признаков от выборки\n","\n","        self.trees: List[DecisionTreeRegressor] = []  # все деревья\n","        self.idxs_array = [] # Added\n","        self.all_ndcg: List[float] = []\n","        self.best_ndcg = float(0.0)\n","\n","    def _get_data(self) -> List[np.ndarray]:\n","        train_df, test_df = msrank_10k()\n","\n","        X_train = train_df.drop([0, 1], axis=1).values\n","        y_train = train_df[0].values\n","        query_ids_train = train_df[1].values.astype(int)\n","\n","        X_test = test_df.drop([0, 1], axis=1).values\n","        y_test = test_df[0].values\n","        query_ids_test = test_df[1].values.astype(int)\n","\n","        return [X_train, y_train, query_ids_train, X_test, y_test, query_ids_test]\n","\n","    def _prepare_data(self) -> None:\n","        (X_train, y_train, self.query_ids_train,\n","         X_test, y_test, self.query_ids_test) = self._get_data()\n","        self.X_train = torch.FloatTensor(self._scale_features_in_query_groups(X_train, self.query_ids_train))\n","        self.ys_train = torch.FloatTensor(y_train)\n","        self.X_test = torch.FloatTensor(self._scale_features_in_query_groups(X_test, self.query_ids_test))\n","        self.ys_test = torch.FloatTensor(y_test)\n","\n","    def _scale_features_in_query_groups(self, inp_feat_array: np.ndarray,\n","                                        inp_query_ids: np.ndarray) -> np.ndarray:\n","        for id in np.unique(inp_query_ids):\n","            scaler = StandardScaler()\n","            idxs = inp_query_ids == id\n","            inp_feat_array[idxs] = scaler.fit_transform(inp_feat_array[idxs])\n","        return inp_feat_array\n","\n","    def _train_one_tree(self, cur_tree_idx: int,\n","                        train_preds: torch.FloatTensor\n","                        ) -> Tuple[DecisionTreeRegressor, np.ndarray]:\n","        \"\"\"\n","        Метод для тренировки одного дерева.\n","\n","        @cur_tree_idx: номер текущего дерева, который предлагается использовать в качестве random_seed для того,\n","        чтобы алгоритм был детерминирован.\n","        @train_preds: суммарные предсказания всех предыдущих деревьев (для расчёта лямбд).\n","        @return: это само дерево и индексы признаков, на которых обучалось дерево\n","        \"\"\"\n","        # Устанавливаем seed для случайных операций\n","        set_seed(cur_tree_idx)\n","\n","        # Создаем словарь с индексами для каждого query_id\n","        query_indices = {}\n","        for i, query_id in enumerate(self.query_ids_train):\n","            if query_id not in query_indices:\n","                query_indices[query_id] = []\n","            query_indices[query_id].append(i)\n","\n","        # Создаем массив лямбда-значений для каждого примера в обучающей выборке\n","        lambdas = torch.zeros_like(train_preds)\n","\n","        # Рассчитываем лямбда-значения для каждого блока данных с одинаковым query_id\n","        for query_id, indices in query_indices.items():\n","            lambdas_query = self._compute_lambdas(self.ys_train[indices], train_preds[indices])\n","            lambdas[indices] = lambdas_query.squeeze()\n","\n","        # Случайным образом выбираем подмножества примеров и признаков для обучения дерева\n","        samples_count = self.X_train.size(dim=0)\n","        features_count = self.X_train.size(dim=1)\n","        samples_indices = torch.full((samples_count,), False)\n","        feature_indices = torch.full((features_count,), False)\n","        for i in range(samples_count):\n","            if np.random.rand() < self.subsample:\n","                samples_indices[i] = True\n","        for i in range(features_count):\n","            if np.random.rand() < self.colsample_bytree:\n","                feature_indices[i] = True\n","\n","        # Выбираем подмножество данных и обучаем дерево решений\n","        sub = self.X_train[samples_indices]\n","        sub = sub[:, feature_indices]\n","        lambdas_sub = lambdas[samples_indices]\n","        dtr = DecisionTreeRegressor(max_depth=self.max_depth, random_state=cur_tree_idx)\n","        dtr.fit(sub, lambdas_sub)\n","\n","        # Сохраняем дерево и индексы признаков\n","        return dtr, torch.where(feature_indices)[0]\n","\n","    def _calc_data_ndcg(self, queries_list: np.ndarray,\n","                        true_labels: torch.FloatTensor, preds: torch.FloatTensor) -> float:\n","        \"\"\" Расчёт метрики по набору данных \"\"\"\n","        score = []\n","        for id in np.unique(queries_list):\n","            idxs = queries_list == id\n","            score.append(ndcg(true_labels[idxs], preds[idxs], gain_scheme=\"exp2\", k=15))\n","        return np.array(score).mean()\n","\n","    def fit(self):\n","        \"\"\"\n","        генеральный метод обучения K деревьев, каждое из которых тренируется\n","        с использованием метода _train_one_tree\n","        \"\"\"\n","        # Устанавливаем seed для воспроизводимости результатов\n","        set_seed(0)\n","\n","        # Создаем массивы для предсказанных значений для обучающей и тестовой выборок\n","        predicted_train = torch.zeros_like(self.ys_train)\n","        predicted_test = torch.zeros_like(self.ys_test)\n","\n","        # Обучаем n_estimators деревьев\n","        for k in tqdm(range(self.n_estimators)):\n","            # Обучаем одно дерево и сохраняем его\n","            tree, feature_indices = self._train_one_tree(k, predicted_train)\n","            self.trees.append(tree)\n","            self.idxs_array.append(feature_indices)\n","\n","            # Применяем обученное дерево к обучающей и тестовой выборкам\n","            prediction_train = tree.predict(self.X_train[:, feature_indices])\n","            prediction_test = tree.predict(self.X_test[:, feature_indices])\n","\n","            # Обновляем предсказанные значения для обучающей и тестовой выборок\n","            predicted_train -= self.lr * prediction_train\n","            predicted_test -= self.lr * prediction_test\n","\n","            # Вычисляем NDCG на тестовой выборке и сохраняем его\n","            ndcg = self._calc_data_ndcg(self.query_ids_test, self.ys_test, predicted_test)\n","            self.all_ndcg.append(ndcg)\n","\n","            # Если текущее значение NDCG лучше, чем лучшее значение, сохраняем его\n","            if ndcg > self.best_ndcg:\n","                self.best_ndcg = ndcg\n","    \n","        # Выбираем лучшее дерево и удаляем оставшиеся\n","        last = self.all_ndcg.index(self.best_ndcg)\n","        self.trees = self.trees[0:last+1]\n","        self.idxs_array = self.idxs_array[0:last+1]\n","\n","        # Выводим лучший результат NDCG\n","        print(f'Total NDCG score {self.best_ndcg}')\n","\n","    def predict(self, data: torch.FloatTensor) -> torch.FloatTensor:\n","        # Выбираем признаки, используемые каждым деревом\n","        feature_indices = torch.tensor(self.idxs_array, dtype=torch.long)\n","        data_subset = torch.index_select(data, dim=1, index=feature_indices)\n","\n","        # Получаем предсказания на всех деревьях\n","        tree_preds = torch.stack([dt.predict(data_subset) for dt in self.trees])\n","\n","        # Вычисляем сумму предсказаний всех деревьев и умножаем на learning rate\n","        ans = -self.lr * torch.sum(tree_preds, dim=0)\n","\n","        return ans\n","\n","    def _compute_lambdas(self, y_true: torch.FloatTensor, y_pred: torch.FloatTensor) -> torch.FloatTensor:\n","        ndcg_scheme = \"exp2\"\n","        ideal_dcg = dcg(y_true, y_true, ndcg_scheme)\n","        N = 0\n","        if ideal_dcg != 0:\n","            N = 1 / ideal_dcg\n","            \n","        y_true_temp = y_true.reshape(-1, 1)\n","        y_pred_temp = y_pred.reshape(-1, 1)\n","        \n","        _, rank_order = torch.sort(y_true_temp, descending=True, axis=0)\n","        rank_order += 1\n","        with torch.no_grad():\n","            # получаем все попарные разницы скоров в батче\n","            pos_pairs_score_diff = 1.0 + torch.exp((y_pred_temp - y_pred_temp.t()))\n","\n","            # поставим разметку для пар, 1 если первый документ релевантнее\n","            # -1 если второй документ релевантнее\n","            Sij = self._compute_labels_in_batch(y_true_temp)\n","            # посчитаем изменение gain из-за перестановок\n","            gain_diff = self._compute_gain_diff(y_true_temp, ndcg_scheme)\n","\n","            # посчитаем изменение знаменателей-дискаунтеров\n","            decay_diff = (1.0 / torch.log2(rank_order + 1.0)) - (1.0 / torch.log2(rank_order.t() + 1.0))\n","            # посчитаем непосредственное изменение nDCG\n","            delta_ndcg = torch.abs(N * gain_diff * decay_diff)\n","            # посчитаем лямбды\n","            lambda_update =  (0.5 * (1 - Sij) - 1 / pos_pairs_score_diff) * delta_ndcg\n","            lambda_update = torch.sum(lambda_update, dim=1, keepdim=True)\n","\n","            return lambda_update\n","\n","    def _compute_labels_in_batch(self, y_true: torch.FloatTensor): ###########\n","        # разница релевантностей каждого с каждым объектом\n","        rel_diff = y_true - y_true.t()\n","\n","        # 1 в этой матрице - объект более релевантен\n","        pos_pairs = (rel_diff > 0).type(torch.float32)\n","\n","        # 1 тут - объект менее релевантен\n","        neg_pairs = (rel_diff < 0).type(torch.float32)\n","        Sij = pos_pairs - neg_pairs\n","        return Sij\n","\n","    def _compute_gain_diff(self, y_true: torch.FloatTensor, gain_scheme: str): ###########\n","        if gain_scheme == \"exp2\":\n","            gain_diff = torch.pow(2.0, y_true) - torch.pow(2.0, y_true.t())\n","        elif gain_scheme == \"diff\":\n","            gain_diff = y_true - y_true.t()\n","        else:\n","            raise ValueError(f\"{gain_scheme} method not supported\")\n","        return gain_diff\n","\n","    def _ndcg_k(self, ys_true, ys_pred, ndcg_top_k) -> float:\n","        try:\n","            return ndcg(ys_true, ys_pred, gain_scheme='exp2', k=ndcg_top_k)\n","        except ZeroDivisionError:\n","            return float(0)\n","\n","    def save_model(self, path: str):\n","        pickle.dump(self, open('%s.lmart' % path, \"wb\"), protocol=2)\n","\n","    def load_model(self, path: str):\n","        model = pickle.load(open(path, \"rb\"))\n","        self.X_train = model.X_train\n","        self.ys_train = model.ys_train\n","        self.X_test = model.X_test\n","        self.ys_test = model.ys_test\n","        self.ndcg_top_k = model.ndcg_top_k\n","        self.n_estimators = model.n_estimators \n","        self.lr = model.lr\n","        self.max_depth = model.max_depth\n","        self.min_samples_leaf = model.min_samples_leaf \n","        self.subsample = model.subsample\n","        self.colsample_bytree = model.colsample_bytree\n","        self.trees = model.trees\n","        self.idxs_array = model.idxs_array\n","        self.all_ndcg = model.all_ndcg\n","        self.best_ndcg = model.best_ndcg"],"metadata":{"id":"NJZJt7cWTTPq","executionInfo":{"status":"ok","timestamp":1683642914160,"user_tz":-180,"elapsed":4,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}}},"id":"NJZJt7cWTTPq","execution_count":6,"outputs":[]},{"cell_type":"markdown","id":"d57f64ef-ec87-48fa-a375-3bcb54efe6c1","metadata":{"id":"d57f64ef-ec87-48fa-a375-3bcb54efe6c1"},"source":["# Домашнее задание № 6\n","\n","Сегодня мы будем  своими руками реализовывать градиентный бустинг на основе вычисления Lambda! \n","\n","В качестве базового алгоритма для бустинга будем использовать ```DecisionTreeRegressor``` из библиотеки ```sklearn```. Как было сказано в лекции, единственное существенное отличие — это целевые метки, на которые обучается каждое дерево: вместо типичных для бустинга ошибок (невязок) используются Lambda-значения. Функцию вычисления лямбд мы рассмотрели на практическом занятии. В решение необходимо осмысленно перенести реализацию в метод ```_compute_lambdas``` класса ```Solution```. \n","\n","## Параметры класса\n","```n_estimators``` — количество деревьев, которые будут строиться в рамках бустинга.\n","\n","```lr``` — Learning Rate, коэффициент, на который умножаются предсказания каждого нового дерева в алгоритме (каждое дерево учится предсказывать значение lambda, но не факт, что добавление к текущим предсказаниям такого значения даст оптимум, поэтому весь “путь” оптимизации разбивается на маленькие шаги).\n","\n","```subsample``` — доля объектов от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n","\n","```colsample_bytree``` — доля признаков от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n","\n","Совокупность двух вышеуказанных параметров позволяет реализовать метод случайных подпространств (смотрите описание по ссылке при необходимости). Понятно, что для применения деревьев (получения предсказания) нужно хранить индексы использованных признаков (но не объектов).\n","\n","```max_depth``` и ```min_samples_leaf``` — параметры ```DecisionTreeRegressor```, отвечающие за глубину построения дерева и минимальное количество в терминальных (финальных) листьях дерева соответственно. \n","\n","## Методы класса\n","```_get_data```, ```_prepare_data```, ```_scale_features_in_query_groups```, ```_ndcg_k``` уже знакомы — можно перенести их реализацию  с тем лишь отличием, что для удобства срезов по индексам размерности ```ys_train``` и ```ys_test``` должны быть N∗1, где N-количество объектов (без этого грейдер будет отчитываться об ошибке).\n","\n","```save_model``` и ```load_model``` — методы, отвечающие за сохранение и загрузку модели. Вам необходимо самостоятельно определить набор полей (их минимум 3), которые нужно сохранять после тренировки и загружать для предсказания. После ```load_model``` необходимо добиться, чтобы модель могла давать те же самые предсказания, что и до сохранения. Сохранение и загрузку реализуйте через модуль ```pickle```. Пример:\n","\n","```bash\n","state = {…}\n","f = open(path, 'wb')\n","pickle.dump(state, f)\n","```\n","\n","Предсказания формируются в методе ```predict```. На вход поступает тензор данных размерности N∗D, где N — количество объектов, D — количество признаков. На выходе ожидается применённый алгоритм бустинга, т.е. тензор предсказаний.\n","\n","Расчёт метрики по набору данных должен производиться методом ```_calc_data_ndcg``` — в нём необходимо проитерироваться по группам запросов, посчитав в каждой ```NDCG```, после чего вернуть усреднённое значение метрики.\n","\n","## Методы для тренировки\n","```_train_one_tree``` — метод для тренировки одного дерева. Принимает на вход ```cur_tree_idx``` — номер текущего дерева, который предлагается использовать в качестве random_seed для того, чтобы алгоритм был детерминирован. ```train_preds``` — суммарные предсказания всех предыдущих деревьев (для расчёта лямбд). В рамках метода необходимо рассчитать лямбды для каждой группы в тренировочном наборе данных, затем применить метод случайных подпространств, сделав срез по признакам (случайно выбранная группа, размер которой задан параметром ```colsample_bytree```) и по объектам (тоже случайно выбранная группа, размер зависит от параметра subsample). Затем произвести тренировку одного ```DecisionTreeRegressor```. Возвращаемые значения — это само дерево и индексы признаков, на которых обучалось дерево.\n","\n","```fit``` — генеральный метод обучения K деревьев, каждое из которых тренируется с использованием метода ```_train_one_tree```. Изначальные предсказания до обучения предлагается приравнять к нулю и от этих значений отталкиваться при обучении первого дерева. Все обученные деревья необходимо сохранить в список, хранящийся в атрибуте trees класса ```Solution```. Для простоты и ускорения работы предлагается рассчитывать предсказания для всех тренировочных и валидационных данных после обучения каждого дерева (но досчитывать только изменения за последнее дерево, храня в памяти предсказания всех предыдущих). Следите за лучшим значением ```NDCG``` (хранить в переменной ```best_ndcg```) — после окончания тренировки нужно обрезать те последние N деревьев, которые лишь ухудшают метрику на валидации. Например, вы обучили 100 деревьев, и лучший результат был достигнут на 78-м. Тогда ```self.trees``` нужно обрезать до 78-го дерева, чтобы модель при предсказании работала лучше всего.\n","\n","## Критерии оценки\n","- Корректная предобработка данных.\n","- Модель адекватно отработала на 1 дереве, ```NDCG``` выше порога случайных предсказаний.\n","- Модель на 100 деревьев на подложенных данных обучается, ```NDCG≥0.425```.\n","- Обученная и сохраненная модель после загрузки корректно дала предсказания в методе ```predict```."]},{"cell_type":"markdown","id":"e092e15c-05d9-4ac8-9b75-c9c1e485be75","metadata":{"id":"e092e15c-05d9-4ac8-9b75-c9c1e485be75"},"source":["# Запуск и сохранение модели"]},{"cell_type":"code","execution_count":7,"id":"a5604709-0971-45ad-a173-847e4796f259","metadata":{"id":"a5604709-0971-45ad-a173-847e4796f259","outputId":"745db121-f54f-4a2f-c28e-9acf8ba5bd67","colab":{"referenced_widgets":["f003fc56fc1a466d98631dce7051baf0","ecb390b5f58344d7bac8abb596e48091","de129fb06db14497b8bd25702c6f9c6f","b690bed5295c4a66a68dac59c2afa4a1","6643d3b20f3a407fa3a37f779924cb27","656818c971cf44cd85e2310e6b39ac21","316eda8d889f4dc2896284bad37979d8","3c74efb930914f47a6d3af9d8fc54c9a","b4836be1803643b3bbbb313918ea055a","9f9563e2a4604e4abf06936a23e0e8df","2a90d3fc893b42f685cf7ee0ae4b7bb0"],"base_uri":"https://localhost:8080/","height":66},"executionInfo":{"status":"ok","timestamp":1683642956742,"user_tz":-180,"elapsed":38406,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f003fc56fc1a466d98631dce7051baf0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Total NDCG score 0.42354342404964096\n"]}],"source":["sol = Solution()\n","sol.fit()\n","sol.save_model(\"model\")\n","sol.load_model(\"model.lmart\")"]},{"cell_type":"code","execution_count":null,"id":"e721bd90-fd8d-44d2-8378-6aa6a6dc9a05","metadata":{"id":"e721bd90-fd8d-44d2-8378-6aa6a6dc9a05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682359067037,"user_tz":-180,"elapsed":8,"user":{"displayName":"Максим Султанкин","userId":"17651215604768188232"}},"outputId":"97b91a37-4d19-4db7-e616-097f48edcd37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["89"]},"metadata":{},"execution_count":14}],"source":["len(sol.trees)"]},{"cell_type":"code","execution_count":null,"id":"da0506c2-1b94-4bdc-a581-806340553db2","metadata":{"id":"da0506c2-1b94-4bdc-a581-806340553db2"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"f003fc56fc1a466d98631dce7051baf0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecb390b5f58344d7bac8abb596e48091","IPY_MODEL_de129fb06db14497b8bd25702c6f9c6f","IPY_MODEL_b690bed5295c4a66a68dac59c2afa4a1"],"layout":"IPY_MODEL_6643d3b20f3a407fa3a37f779924cb27"}},"ecb390b5f58344d7bac8abb596e48091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_656818c971cf44cd85e2310e6b39ac21","placeholder":"​","style":"IPY_MODEL_316eda8d889f4dc2896284bad37979d8","value":"100%"}},"de129fb06db14497b8bd25702c6f9c6f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c74efb930914f47a6d3af9d8fc54c9a","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4836be1803643b3bbbb313918ea055a","value":100}},"b690bed5295c4a66a68dac59c2afa4a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f9563e2a4604e4abf06936a23e0e8df","placeholder":"​","style":"IPY_MODEL_2a90d3fc893b42f685cf7ee0ae4b7bb0","value":" 100/100 [00:34&lt;00:00,  2.71it/s]"}},"6643d3b20f3a407fa3a37f779924cb27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"656818c971cf44cd85e2310e6b39ac21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"316eda8d889f4dc2896284bad37979d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c74efb930914f47a6d3af9d8fc54c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4836be1803643b3bbbb313918ea055a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f9563e2a4604e4abf06936a23e0e8df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a90d3fc893b42f685cf7ee0ae4b7bb0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}